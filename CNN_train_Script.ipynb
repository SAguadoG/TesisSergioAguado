{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CNN Train Script",
   "id": "b9fa683acce4e34d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Este es el archivo donde se hará una prueba de clasificador automático mediante CNN (Convolutional Neural Network).",
   "id": "79203c842a7fc34a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "De manera independiente se van a cargar las librerías necesarias para el script.\n",
    "A la hora de realizar este script, Tensorflow/Keras no es aún compatible con Python 3.12, así que se usará la versión de Python 3.11.6"
   ],
   "id": "9e81c3a5c39d3c85"
  },
  {
   "cell_type": "code",
   "id": "a7b233b096c81103",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-10T19:39:16.647201Z",
     "start_time": "2024-12-10T19:39:16.642656Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Para puntualizar ahora mismo, se añadirán mas tipos en un futuro.\n",
    "1. original_signals → Etiqueta 0.\n",
    "2. flicker_signals → Etiqueta 1.\n",
    "3. harmonic_signals → Etiqueta 2.\n",
    "4. Interruption_signals → Etiqueta 3.\n",
    "5. original_signals → Etiqueta 4.\n",
    "6. Swell_signals → Etiqueta 5.\n",
    "7. transient_signals → Etiqueta 6."
   ],
   "id": "6d9872572e7fe718"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T19:39:22.116368Z",
     "start_time": "2024-12-10T19:39:16.648565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_signal(signal):\n",
    "\n",
    "    # Parámetros teóricos\n",
    "    max_theoretical_value = 230 * np.sqrt(2)\n",
    "\n",
    "    # Media de la señal\n",
    "    mean_value = np.mean(signal)\n",
    "\n",
    "    # Datos sin sesgo\n",
    "    unbias_data = signal - mean_value\n",
    "    unbias_data_2 = unbias_data ** 2\n",
    "    unbias_data_3 = unbias_data_2 * unbias_data\n",
    "    unbias_data_4 = unbias_data_3 * unbias_data\n",
    "\n",
    "    # Cálculo de características\n",
    "    variance = np.var(unbias_data)  # Varianza\n",
    "    skewness = np.mean(unbias_data_3) / (variance ** 1.5)  # Asimetría\n",
    "    kurtosis = np.mean(unbias_data_4) / (variance ** 2) - 3  # Curtosis\n",
    "    thd = np.sqrt(np.sum(np.abs(np.fft.fft(signal)[2:4])) / np.abs(np.fft.fft(signal)[1]))  # Distorsión armónica total\n",
    "    rms = np.sqrt(np.mean(signal ** 2))  # Valor RMS\n",
    "    crest_factor = np.max(signal) / rms  # Factor de cresta\n",
    "\n",
    "    # Devuelve todas las características en un vector\n",
    "    return np.array([variance, skewness, kurtosis, thd, crest_factor])\n",
    "\n",
    "def load_signal(data_path):\n",
    "\n",
    "    # Inicialización de listas para características y etiquetas\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterar por cada tipo de perturbación\n",
    "    for label, signal_type in enumerate(os.listdir(data_path)):\n",
    "        signal_type_path = os.path.join(data_path, signal_type)\n",
    "\n",
    "        # Asegurarse de que sea un directorio\n",
    "        if os.path.isdir(signal_type_path):\n",
    "            for subset in [\"train\", \"test\", \"val\"]:\n",
    "                subset_path = os.path.join(signal_type_path, subset)\n",
    "                \n",
    "                if os.path.exists(subset_path):\n",
    "                    for filename in os.listdir(subset_path):\n",
    "                        if filename.endswith(\".npy\"):\n",
    "                            file_path = os.path.join(subset_path, filename)\n",
    "\n",
    "                            # Cargar la señal\n",
    "                            signal = np.load(file_path)\n",
    "\n",
    "                            # Procesar la señal y extraer características\n",
    "                            feature_vector = preprocess_signal(signal)\n",
    "\n",
    "                            # Agregar las características y etiquetas a las listas\n",
    "                            features.append(feature_vector)\n",
    "                            labels.append(label)\n",
    "\n",
    "    # Convertir a numpy arrays para facilitar el uso posterior\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Ejemplo de uso\n",
    "data_path = \"data\"  # Ajusta esta ruta según sea necesario\n",
    "features, labels = load_signal(data_path)\n",
    "\n",
    "print(f\"Características extraídas: {features.shape}\")\n",
    "print(f\"Etiquetas extraídas: {labels.shape}\")\n",
    "\n",
    "# Inspeccionar las etiquetas únicas\n",
    "print(\"Etiquetas únicas:\", np.unique(labels))\n",
    "\n",
    "# Contar cuántas señales hay por categoría\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "print(\"Distribución de señales por categoría:\")\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"Clase {label}: {count} señales\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características extraídas: (25200, 5)\n",
      "Etiquetas extraídas: (25200,)\n",
      "Etiquetas únicas: [0 1 2 4 5 6 7]\n",
      "Distribución de señales por categoría:\n",
      "Clase 0: 3600 señales\n",
      "Clase 1: 3600 señales\n",
      "Clase 2: 3600 señales\n",
      "Clase 4: 3600 señales\n",
      "Clase 5: 3600 señales\n",
      "Clase 6: 3600 señales\n",
      "Clase 7: 3600 señales\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T19:39:22.138666Z",
     "start_time": "2024-12-10T19:39:22.117433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Dividir los datos en entrenamiento, validación y prueba\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Verificar la forma de las características y etiquetas\n",
    "print(f\"Características de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Características de validación: {X_val.shape}\")\n",
    "print(f\"Características de prueba: {X_test.shape}\")\n",
    "print(f\"Etiquetas de entrenamiento: {y_train.shape}\")\n",
    "print(f\"Etiquetas de validación: {y_val.shape}\")\n",
    "print(f\"Etiquetas de prueba: {y_test.shape}\")\n",
    "\n",
    "# Si las etiquetas no están en formato one-hot, convertirlas\n",
    "# Esto es necesario solo si decides usar categorical_crossentropy\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=7)\n",
    "y_val_one_hot = to_categorical(y_val, num_classes=7)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=7)\n",
    "\n",
    "# Definir el modelo\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Capa de entrada\n",
    "    Dense(32, activation='relu'),  # Capa oculta\n",
    "    Dense(7, activation='softmax')  # Capa de salida (7 clases)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',  # Pérdida para clasificación multiclase (one-hot encoded)\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    validation_data=(X_val, y_val_one_hot),\n",
    "                    epochs=50,\n",
    "                    batch_size=32)\n",
    "\n",
    "# Evaluar el modelo en los datos de prueba\n",
    "loss, accuracy = model.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")"
   ],
   "id": "d88dae4836c64e07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características de entrenamiento: (17640, 5)\n",
      "Características de validación: (3780, 5)\n",
      "Características de prueba: (3780, 5)\n",
      "Etiquetas de entrenamiento: (17640,)\n",
      "Etiquetas de validación: (3780,)\n",
      "Etiquetas de prueba: (3780,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 7 is out of bounds for axis 1 with size 7",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 22\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEtiquetas de prueba: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00my_test\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Si las etiquetas no están en formato one-hot, convertirlas\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Esto es necesario solo si decides usar categorical_crossentropy\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m y_train_one_hot \u001B[38;5;241m=\u001B[39m \u001B[43mto_categorical\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m7\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m y_val_one_hot \u001B[38;5;241m=\u001B[39m to_categorical(y_val, num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m7\u001B[39m)\n\u001B[1;32m     24\u001B[0m y_test_one_hot \u001B[38;5;241m=\u001B[39m to_categorical(y_test, num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m7\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/TesisSergioAguado/.venv/lib/python3.11/site-packages/keras/src/utils/numerical_utils.py:99\u001B[0m, in \u001B[0;36mto_categorical\u001B[0;34m(x, num_classes)\u001B[0m\n\u001B[1;32m     97\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     98\u001B[0m categorical \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((batch_size, num_classes))\n\u001B[0;32m---> 99\u001B[0m \u001B[43mcategorical\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marange\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    100\u001B[0m output_shape \u001B[38;5;241m=\u001B[39m input_shape \u001B[38;5;241m+\u001B[39m (num_classes,)\n\u001B[1;32m    101\u001B[0m categorical \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mreshape(categorical, output_shape)\n",
      "\u001B[0;31mIndexError\u001B[0m: index 7 is out of bounds for axis 1 with size 7"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Gráfico de pérdida\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de precisión\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "b866329d3d8b905c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
