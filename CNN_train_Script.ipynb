{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CNN Train Script",
   "id": "b9fa683acce4e34d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Este es el archivo donde se hará una prueba de clasificador automático mediante CNN (Convolutional Neural Network).",
   "id": "79203c842a7fc34a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "De manera independiente se van a cargar las librerías necesarias para el script.\n",
    "A la hora de realizar este script, Tensorflow/Keras no es aún compatible con Python 3.12, así que se usará la versión de Python 3.11.6"
   ],
   "id": "9e81c3a5c39d3c85"
  },
  {
   "cell_type": "code",
   "id": "a7b233b096c81103",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-06T14:35:11.663797Z",
     "start_time": "2025-01-06T14:35:09.202706Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Para puntualizar ahora mismo, se añadirán mas tipos en un futuro.\n",
    "1. original_signals → Etiqueta 0.\n",
    "2. flicker_signals → Etiqueta 1.\n",
    "3. harmonic_signals → Etiqueta 2.\n",
    "4. Interruption_signals → Etiqueta 3.\n",
    "5. original_signals → Etiqueta 4.\n",
    "6. Swell_signals → Etiqueta 5.\n",
    "7. transient_signals → Etiqueta 6."
   ],
   "id": "6d9872572e7fe718"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T14:35:24.578703Z",
     "start_time": "2025-01-06T14:35:11.665218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_signal(signal):\n",
    "\n",
    "    # Parámetros teóricos\n",
    "    max_theoretical_value = 230 * np.sqrt(2)\n",
    "\n",
    "    # Media de la señal\n",
    "    mean_value = np.mean(signal)\n",
    "\n",
    "    # Datos sin sesgo\n",
    "    unbias_data = signal - mean_value\n",
    "    unbias_data_2 = unbias_data ** 2\n",
    "    unbias_data_3 = unbias_data_2 * unbias_data\n",
    "    unbias_data_4 = unbias_data_3 * unbias_data\n",
    "\n",
    "    # Cálculo de características\n",
    "    variance = np.var(unbias_data)  # Varianza\n",
    "    skewness = np.mean(unbias_data_3) / (variance ** 1.5)  # Asimetría\n",
    "    kurtosis = np.mean(unbias_data_4) / (variance ** 2) - 3  # Curtosis\n",
    "    thd = np.sqrt(np.sum(np.abs(np.fft.fft(signal)[2:4])) / np.abs(np.fft.fft(signal)[1]))  # Distorsión armónica total\n",
    "    rms = np.sqrt(np.mean(signal ** 2))  # Valor RMS\n",
    "    crest_factor = np.max(signal) / rms  # Factor de cresta\n",
    "\n",
    "    # Devuelve todas las características en un vector\n",
    "    return np.array([variance, skewness, kurtosis, thd, crest_factor])\n",
    "\n",
    "def load_signal(data_path):\n",
    "\n",
    "    # Asignar etiquetas explícitamente\n",
    "    label_mapping = {\n",
    "        \"flicker_signals\": 0,\n",
    "        \"harmonic_signals\": 1,\n",
    "        \"interruption_signals\": 2,\n",
    "        \"original_signal\": 3,\n",
    "        \"sag_signals\": 4,\n",
    "        \"swell_signals\": 5,\n",
    "        \"transient_signals\": 6,\n",
    "    }\n",
    "\n",
    "    # Inicialización de listas para características y etiquetas\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterar por cada tipo de perturbación\n",
    "    for signal_type, label in label_mapping.items():\n",
    "        signal_type_path = os.path.join(data_path, signal_type)\n",
    "\n",
    "        if os.path.isdir(signal_type_path):\n",
    "            for subset in [\"train\", \"test\", \"val\"]:\n",
    "                subset_path = os.path.join(signal_type_path, subset)\n",
    "\n",
    "                if os.path.exists(subset_path):\n",
    "                    for filename in os.listdir(subset_path):\n",
    "                        if filename.endswith(\".npy\"):\n",
    "                            file_path = os.path.join(subset_path, filename)\n",
    "\n",
    "                            # Cargar la señal\n",
    "                            signal = np.load(file_path)\n",
    "\n",
    "                            # Procesar la señal y extraer características\n",
    "                            feature_vector = preprocess_signal(signal)\n",
    "\n",
    "                            # Agregar las características y etiquetas a las listas\n",
    "                            features.append(feature_vector)\n",
    "                            labels.append(label)\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Ejemplo de uso\n",
    "data_path = \"data\"  # Ajusta esta ruta según sea necesario\n",
    "features, labels = load_signal(data_path)\n",
    "\n",
    "print(f\"Características extraídas: {features.shape}\")\n",
    "print(f\"Etiquetas extraídas: {labels.shape}\")\n",
    "\n",
    "\n",
    "# Contar las etiquetas únicas en los datos originales \n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "print(\"Etiquetas únicas:\", unique_labels)\n",
    "print(\"Distribución de señales por categoría:\")\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Clase {label}: {count} señales\")\n",
    "\n",
    "# Verificar que la clase 3 está presente\n",
    "if 3 not in unique_labels: \n",
    "    print(\"Error: La clase 3 no está presente en los datos originales.\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características extraídas: (25200, 5)\n",
      "Etiquetas extraídas: (25200,)\n",
      "Etiquetas únicas: [0 1 2 3 4 5 6]\n",
      "Distribución de señales por categoría:\n",
      "Clase 0: 3600 señales\n",
      "Clase 1: 3600 señales\n",
      "Clase 2: 3600 señales\n",
      "Clase 3: 3600 señales\n",
      "Clase 4: 3600 señales\n",
      "Clase 5: 3600 señales\n",
      "Clase 6: 3600 señales\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T14:35:24.883776Z",
     "start_time": "2025-01-06T14:35:24.579404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dividir los datos en entrenamiento, validación y prueba\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(features, labels, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Verificar la forma de las características y etiquetas\n",
    "print(f\"Características de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Características de validación: {X_val.shape}\")\n",
    "print(f\"Características de prueba: {X_test.shape}\")\n",
    "print(f\"Etiquetas de entrenamiento: {y_train.shape}\")\n",
    "print(f\"Etiquetas de validación: {y_val.shape}\")\n",
    "print(f\"Etiquetas de prueba: {y_test.shape}\")\n",
    "\n",
    "# Si las etiquetas no están en formato one-hot, convertirlas\n",
    "# Esto es necesario solo si decides usar categorical_crossentropy\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=7)\n",
    "y_val_one_hot = to_categorical(y_val, num_classes=7)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=7)\n",
    "\n",
    "# Definir el modelo\n",
    "model = Sequential([\n",
    "    Dense(128, activation='tanh',kernel_regularizer=l2(0.001) ,input_shape=(X_train.shape[1],)),  # Capa de entrada\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='tanh'),  # Capa oculta\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='tanh'),  # Capa Oculta\n",
    "    Dense(7, activation='softmax')  # Capa de salida (7 clases)\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',  # Pérdida para clasificación multiclase (one-hot encoded)\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train_one_hot,\n",
    "                    validation_data=(X_val, y_val_one_hot),\n",
    "                    epochs=50,\n",
    "                    batch_size=32)\n",
    "\n",
    "# Evaluar el modelo en los datos de prueba\n",
    "loss, accuracy = model.evaluate(X_test, y_test_one_hot)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Obtener las predicciones del modelo en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test_one_hot, axis=1)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print(\"Matriz de Confusión:\\n\", conf_matrix)\n",
    "\n",
    "# Calcular el informe de clasificación\n",
    "class_report = classification_report(y_test_classes, y_pred_classes)\n",
    "print(\"Informe de Clasificación:\\n\", class_report)\n"
   ],
   "id": "d88dae4836c64e07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características de entrenamiento: (17640, 5)\n",
      "Características de validación: (3780, 5)\n",
      "Características de prueba: (3780, 5)\n",
      "Etiquetas de entrenamiento: (17640,)\n",
      "Etiquetas de validación: (3780,)\n",
      "Etiquetas de prueba: (3780,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 15:35:24.589638: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2025-01-06 15:35:24.589669: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2025-01-06 15:35:24.589676: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2025-01-06 15:35:24.589859: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-01-06 15:35:24.589870: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/saguadog/Documents/TesisSergioAguado/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 5)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m y_test_one_hot \u001B[38;5;241m=\u001B[39m to_categorical(y_test, num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m7\u001B[39m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Definir el modelo\u001B[39;00m\n\u001B[0;32m---> 20\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mSequential\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mLSTM\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactivation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtanh\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mkernel_regularizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43ml2\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.001\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m,\u001B[49m\u001B[43minput_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Capa de entrada\u001B[39;49;00m\n\u001B[1;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mDropout\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mLSTM\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactivation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtanh\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Capa oculta\u001B[39;49;00m\n\u001B[1;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mDropout\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mLSTM\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactivation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtanh\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Capa Oculta\u001B[39;49;00m\n\u001B[1;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43mDense\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m7\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactivation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msoftmax\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Capa de salida (7 clases)\u001B[39;49;00m\n\u001B[1;32m     27\u001B[0m \u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# Compilar el modelo\u001B[39;00m\n\u001B[1;32m     30\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(optimizer\u001B[38;5;241m=\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0001\u001B[39m),\n\u001B[1;32m     31\u001B[0m               loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m# Pérdida para clasificación multiclase (one-hot encoded)\u001B[39;00m\n\u001B[1;32m     32\u001B[0m               metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m~/Documents/TesisSergioAguado/.venv/lib/python3.11/site-packages/keras/src/models/sequential.py:76\u001B[0m, in \u001B[0;36mSequential.__init__\u001B[0;34m(self, layers, trainable, name)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m layers:\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd(layer, rebuild\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m---> 76\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_maybe_rebuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/TesisSergioAguado/.venv/lib/python3.11/site-packages/keras/src/models/sequential.py:141\u001B[0m, in \u001B[0;36mSequential._maybe_rebuild\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers[\u001B[38;5;241m0\u001B[39m], InputLayer) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    140\u001B[0m     input_shape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mbatch_shape\n\u001B[0;32m--> 141\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_shape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minput_shape\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;66;03m# We can build the Sequential model if the first layer has the\u001B[39;00m\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001B[39;00m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;66;03m# model.\u001B[39;00m\n\u001B[1;32m    146\u001B[0m     input_shape \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39minput_shape\n",
      "File \u001B[0;32m~/Documents/TesisSergioAguado/.venv/lib/python3.11/site-packages/keras/src/layers/layer.py:226\u001B[0m, in \u001B[0;36mLayer.__new__.<locals>.build_wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_open_name_scope():\n\u001B[1;32m    225\u001B[0m     obj\u001B[38;5;241m.\u001B[39m_path \u001B[38;5;241m=\u001B[39m current_path()\n\u001B[0;32m--> 226\u001B[0m     \u001B[43moriginal_build_method\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m \u001B[38;5;66;03m# Record build config.\u001B[39;00m\n\u001B[1;32m    228\u001B[0m signature \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39msignature(original_build_method)\n",
      "File \u001B[0;32m~/Documents/TesisSergioAguado/.venv/lib/python3.11/site-packages/keras/src/models/sequential.py:187\u001B[0m, in \u001B[0;36mSequential.build\u001B[0;34m(self, input_shape)\u001B[0m\n\u001B[1;32m    185\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_layers[\u001B[38;5;241m1\u001B[39m:]:\n\u001B[1;32m    186\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 187\u001B[0m         x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m:\n\u001B[1;32m    189\u001B[0m         \u001B[38;5;66;03m# Can happen if shape inference is not implemented.\u001B[39;00m\n\u001B[1;32m    190\u001B[0m         \u001B[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001B[39;00m\n\u001B[1;32m    191\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[0;32m~/Documents/TesisSergioAguado/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/Documents/TesisSergioAguado/.venv/lib/python3.11/site-packages/keras/src/layers/input_spec.py:186\u001B[0m, in \u001B[0;36massert_input_compatibility\u001B[0;34m(input_spec, inputs, layer_name)\u001B[0m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m spec\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m spec\u001B[38;5;241m.\u001B[39mallow_last_axis_squeeze:\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ndim \u001B[38;5;241m!=\u001B[39m spec\u001B[38;5;241m.\u001B[39mndim:\n\u001B[0;32m--> 186\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    187\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mInput \u001B[39m\u001B[38;5;132;01m{\u001B[39;00minput_index\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m of layer \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlayer_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    188\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis incompatible with the layer: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    189\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexpected ndim=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mspec\u001B[38;5;241m.\u001B[39mndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, found ndim=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mndim\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    190\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFull shape received: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    191\u001B[0m         )\n\u001B[1;32m    192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m spec\u001B[38;5;241m.\u001B[39mmax_ndim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    193\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ndim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m ndim \u001B[38;5;241m>\u001B[39m spec\u001B[38;5;241m.\u001B[39mmax_ndim:\n",
      "\u001B[0;31mValueError\u001B[0m: Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 5)"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Gráfico de pérdida\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de precisión\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "b866329d3d8b905c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
