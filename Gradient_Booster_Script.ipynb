{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-21T21:08:39.242645Z",
     "start_time": "2025-01-21T21:08:39.239934Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T21:09:09.901591Z",
     "start_time": "2025-01-21T21:08:39.243818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_signal(signal):\n",
    "    # Parámetros teóricos\n",
    "    max_theoretical_value = 230 * np.sqrt(2)\n",
    "\n",
    "    # Media de la señal\n",
    "    mean_value = np.mean(signal)\n",
    "\n",
    "    # Datos sin sesgo\n",
    "    unbias_data = signal - mean_value\n",
    "    unbias_data_2 = unbias_data ** 2\n",
    "    unbias_data_3 = unbias_data_2 * unbias_data\n",
    "    unbias_data_4 = unbias_data_3 * unbias_data\n",
    "\n",
    "    # Cálculo de características\n",
    "    variance = np.var(unbias_data)  # Varianza\n",
    "    skewness = np.mean(unbias_data_3) / (variance ** 1.5)  # Asimetría\n",
    "    kurtosis = np.mean(unbias_data_4) / (variance ** 2) - 3  # Curtosis\n",
    "    thd = np.sqrt(np.sum(np.abs(np.fft.fft(signal)[2:4])) / np.abs(np.fft.fft(signal)[1]))  # Distorsión armónica total\n",
    "    rms = np.sqrt(np.mean(signal ** 2))  # Valor RMS\n",
    "    crest_factor = np.max(signal) / rms  # Factor de cresta\n",
    "\n",
    "    # Devuelve todas las características en un vector\n",
    "    return np.array([variance, skewness, kurtosis, thd, crest_factor])\n",
    "\n",
    "def load_signal(data_path):\n",
    "    # Asignar etiquetas explícitamente\n",
    "    label_mapping = {\n",
    "        \"flicker_signals\": 0,\n",
    "        \"harmonic_signals\": 1,\n",
    "        \"interruption_signals\": 2,\n",
    "        \"original_signals\": 3,\n",
    "        \"sag_signals\": 4,\n",
    "        \"swell_signals\": 5,\n",
    "        \"transient_signals\": 6,\n",
    "    }\n",
    "\n",
    "    # Inicialización de listas para características y etiquetas\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterar por cada tipo de perturbación\n",
    "    for signal_type, label in label_mapping.items():\n",
    "        signal_type_path = os.path.join(data_path, signal_type)\n",
    "\n",
    "        if os.path.isdir(signal_type_path):\n",
    "            for subset in [\"train\", \"test\", \"val\"]:\n",
    "                subset_path = os.path.join(signal_type_path, subset)\n",
    "\n",
    "                if os.path.exists(subset_path):\n",
    "                    for filename in os.listdir(subset_path):\n",
    "                        if filename.endswith(\".npy\"):\n",
    "                            file_path = os.path.join(subset_path, filename)\n",
    "\n",
    "                            # Cargar la señal\n",
    "                            try:\n",
    "                                signal = np.load(file_path)\n",
    "\n",
    "                                # Validación adicional: asegurarse de que los datos sean válidos\n",
    "                                if signal.size == 0:\n",
    "                                    print(f\"Advertencia: {file_path} está vacío y será ignorado.\")\n",
    "                                    continue\n",
    "\n",
    "                                # Procesar la señal y extraer características\n",
    "                                feature_vector = preprocess_signal(signal)\n",
    "\n",
    "                                # Agregar las características y etiquetas a las listas\n",
    "                                features.append(feature_vector)\n",
    "                                labels.append(label)\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error al cargar {file_path}: {e}\")\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Ejemplo de uso\n",
    "data_path = \"data\"  # Ajusta esta ruta según sea necesario\n",
    "features, labels = load_signal(data_path)\n",
    "\n",
    "print(f\"Características extraídas: {features.shape}\")\n",
    "print(f\"Etiquetas extraídas: {labels.shape}\")\n",
    "\n",
    "# Contar las etiquetas únicas en los datos originales \n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "print(\"Etiquetas únicas:\", unique_labels)\n",
    "print(\"Distribución de señales por categoría:\")\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Clase {label}: {count} señales\")\n",
    "\n",
    "# Verificar que la clase 3 está presente\n",
    "if 3 not in unique_labels: \n",
    "    print(\"Advertencia: La clase 3 no está presente en los datos originales, esto puede afectar el modelo.\")"
   ],
   "id": "77daad9b916b08ed",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características extraídas: (75600, 5)\n",
      "Etiquetas extraídas: (75600,)\n",
      "Etiquetas únicas: [0 1 2 3 4 5 6]\n",
      "Distribución de señales por categoría:\n",
      "Clase 0: 10800 señales\n",
      "Clase 1: 10800 señales\n",
      "Clase 2: 10800 señales\n",
      "Clase 3: 10800 señales\n",
      "Clase 4: 10800 señales\n",
      "Clase 5: 10800 señales\n",
      "Clase 6: 10800 señales\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T21:09:14.106452Z",
     "start_time": "2025-01-21T21:09:09.902453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Crear el modelo de Gradient Boosting\n",
    "GradBoost = HistGradientBoostingClassifier(\n",
    "    max_iter=100,  # Número de iteraciones (boosting rounds)\n",
    "    loss='log_loss',  # Pérdida para clasificación (log_loss para multiclase)\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "GradBoost.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones\n",
    "predicciones = GradBoost.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_test, predicciones)\n",
    "print(f\"Accuracy en el conjunto de prueba: {accuracy:.2f}\")\n",
    "\n",
    "# Generar el informe de clasificación\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, predicciones))\n",
    "\n",
    "# Matriz de confusión\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "conf_matrix = confusion_matrix(y_test, predicciones)\n",
    "print(conf_matrix)"
   ],
   "id": "fcffe6f9ce65b25",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en el conjunto de prueba: 0.99\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2160\n",
      "           1       0.99      0.98      0.99      2160\n",
      "           2       0.95      0.99      0.97      2160\n",
      "           3       1.00      1.00      1.00      2160\n",
      "           4       0.98      0.95      0.97      2160\n",
      "           5       0.99      0.99      0.99      2160\n",
      "           6       1.00      1.00      1.00      2160\n",
      "\n",
      "    accuracy                           0.99     15120\n",
      "   macro avg       0.99      0.99      0.99     15120\n",
      "weighted avg       0.99      0.99      0.99     15120\n",
      "\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[2160    0    0    0    0    0    0]\n",
      " [   0 2116    1    1   18   23    1]\n",
      " [   0    0 2140    0   20    0    0]\n",
      " [   0    0    0 2160    0    0    0]\n",
      " [   0    1  105    0 2054    0    0]\n",
      " [   0   11    0    0    0 2147    2]\n",
      " [   0    1    0    0    0    1 2158]]\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
