{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-13T23:54:40.282005Z",
     "start_time": "2025-01-13T23:54:40.279226Z"
    }
   },
   "source": [
    "# Data Processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Tree Visualisation\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "43cdcd19cc1d47b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:54:45.875371Z",
     "start_time": "2025-01-13T23:54:40.290500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_signal(signal):\n",
    "\n",
    "    # Parámetros teóricos\n",
    "    max_theoretical_value = 230 * np.sqrt(2)\n",
    "\n",
    "    # Media de la señal\n",
    "    mean_value = np.mean(signal)\n",
    "\n",
    "    # Datos sin sesgo\n",
    "    unbias_data = signal - mean_value\n",
    "    unbias_data_2 = unbias_data ** 2\n",
    "    unbias_data_3 = unbias_data_2 * unbias_data\n",
    "    unbias_data_4 = unbias_data_3 * unbias_data\n",
    "\n",
    "    # Cálculo de características\n",
    "    variance = np.var(unbias_data)  # Varianza\n",
    "    skewness = np.mean(unbias_data_3) / (variance ** 1.5)  # Asimetría\n",
    "    kurtosis = np.mean(unbias_data_4) / (variance ** 2) - 3  # Curtosis\n",
    "    thd = np.sqrt(np.sum(np.abs(np.fft.fft(signal)[2:4])) / np.abs(np.fft.fft(signal)[1]))  # Distorsión armónica total\n",
    "    rms = np.sqrt(np.mean(signal ** 2))  # Valor RMS\n",
    "    crest_factor = np.max(signal) / rms  # Factor de cresta\n",
    "\n",
    "    # Devuelve todas las características en un vector\n",
    "    return np.array([variance, skewness, kurtosis, thd, crest_factor])\n",
    "\n",
    "def load_signal(data_path):\n",
    "\n",
    "    # Asignar etiquetas explícitamente\n",
    "    label_mapping = {\n",
    "        \"flicker_signals\": 0,\n",
    "        \"harmonic_signals\": 1,\n",
    "        \"interruption_signals\": 2,\n",
    "        \"original_signal\": 3,\n",
    "        \"sag_signals\": 4,\n",
    "        \"swell_signals\": 5,\n",
    "        \"transient_signals\": 6,\n",
    "    }\n",
    "\n",
    "    # Inicialización de listas para características y etiquetas\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterar por cada tipo de perturbación\n",
    "    for signal_type, label in label_mapping.items():\n",
    "        signal_type_path = os.path.join(data_path, signal_type)\n",
    "\n",
    "        if os.path.isdir(signal_type_path):\n",
    "            for subset in [\"train\", \"test\", \"val\"]:\n",
    "                subset_path = os.path.join(signal_type_path, subset)\n",
    "\n",
    "                if os.path.exists(subset_path):\n",
    "                    for filename in os.listdir(subset_path):\n",
    "                        if filename.endswith(\".npy\"):\n",
    "                            file_path = os.path.join(subset_path, filename)\n",
    "\n",
    "                            # Cargar la señal\n",
    "                            signal = np.load(file_path)\n",
    "\n",
    "                            # Procesar la señal y extraer características\n",
    "                            feature_vector = preprocess_signal(signal)\n",
    "\n",
    "                            # Agregar las características y etiquetas a las listas\n",
    "                            features.append(feature_vector)\n",
    "                            labels.append(label)\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Ejemplo de uso\n",
    "data_path = \"data\"  # Ajusta esta ruta según sea necesario\n",
    "features, labels = load_signal(data_path)\n",
    "\n",
    "print(f\"Características extraídas: {features.shape}\")\n",
    "print(f\"Etiquetas extraídas: {labels.shape}\")\n",
    "\n",
    "\n",
    "# Contar las etiquetas únicas en los datos originales \n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "print(\"Etiquetas únicas:\", unique_labels)\n",
    "print(\"Distribución de señales por categoría:\")\n",
    "for label, count in zip(unique_labels, counts):\n",
    "    print(f\"Clase {label}: {count} señales\")\n",
    "\n",
    "# Verificar que la clase 3 está presente\n",
    "if 3 not in unique_labels: \n",
    "    print(\"Error: La clase 3 no está presente en los datos originales.\")"
   ],
   "id": "885135c1f212f8a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características extraídas: (25200, 5)\n",
      "Etiquetas extraídas: (25200,)\n",
      "Etiquetas únicas: [0 1 2 3 4 5 6]\n",
      "Distribución de señales por categoría:\n",
      "Clase 0: 3600 señales\n",
      "Clase 1: 3600 señales\n",
      "Clase 2: 3600 señales\n",
      "Clase 3: 3600 señales\n",
      "Clase 4: 3600 señales\n",
      "Clase 5: 3600 señales\n",
      "Clase 6: 3600 señales\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ad0503e044cbf0cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-13T23:54:47.862693Z",
     "start_time": "2025-01-13T23:54:45.876218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo base\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy del modelo de Random Forest: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualizar el árbol de decisión (opcional)\n",
    "# Export the first three decision trees from the forest\n",
    "\n",
    "for i in range(3):\n",
    "    tree = rf_model.estimators_[i]\n",
    "    dot_data = export_graphviz(tree,\n",
    "                               feature_names=X_train.columns,  \n",
    "                               filled=True,  \n",
    "                               max_depth=2, \n",
    "                               impurity=False, \n",
    "                               proportion=True)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)"
   ],
   "id": "874ed938d34d99f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo de Random Forest: 0.99\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       731\n",
      "           1       0.99      0.99      0.99       713\n",
      "           2       0.93      1.00      0.96       741\n",
      "           3       1.00      1.00      1.00       695\n",
      "           4       0.99      0.93      0.96       743\n",
      "           5       1.00      1.00      1.00       698\n",
      "           6       1.00      1.00      1.00       719\n",
      "\n",
      "    accuracy                           0.99      5040\n",
      "   macro avg       0.99      0.99      0.99      5040\n",
      "weighted avg       0.99      0.99      0.99      5040\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[33], line 23\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m3\u001B[39m):\n\u001B[1;32m     21\u001B[0m     tree \u001B[38;5;241m=\u001B[39m rf_model\u001B[38;5;241m.\u001B[39mestimators_[i]\n\u001B[1;32m     22\u001B[0m     dot_data \u001B[38;5;241m=\u001B[39m export_graphviz(tree,\n\u001B[0;32m---> 23\u001B[0m                                feature_names\u001B[38;5;241m=\u001B[39m\u001B[43mX_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m,  \n\u001B[1;32m     24\u001B[0m                                filled\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,  \n\u001B[1;32m     25\u001B[0m                                max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, \n\u001B[1;32m     26\u001B[0m                                impurity\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, \n\u001B[1;32m     27\u001B[0m                                proportion\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     28\u001B[0m     graph \u001B[38;5;241m=\u001B[39m graphviz\u001B[38;5;241m.\u001B[39mSource(dot_data)\n\u001B[1;32m     29\u001B[0m     display(graph)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
